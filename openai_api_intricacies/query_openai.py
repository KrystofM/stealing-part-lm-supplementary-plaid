# %%
import asyncio
from openai import AsyncOpenAI, OpenAI
from dotenv import load_dotenv
import tiktoken

load_dotenv()

# client = OpenAI(timeout=10.0, max_retries=1)


# %%
# Function to get token IDs for a given model family
def get_token_ids(model_family, text):
    if "gpt-4" in model_family:
        model_enc = tiktoken.encoding_for_model("gpt-4")
    elif "gpt-3.5-turbo" in model_family:
        model_enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
    elif (
        "ada" in model_family
        or "babbage" in model_family
        or "curie" in model_family
        or "davinci" in model_family
    ):
        model_enc = tiktoken.encoding_for_model("davinci")
    return model_enc.encode(text)


model_name = "gpt-3.5-turbo-1106"
# Adjust these for your use-case
logit_bias_values = {
    "happy": get_token_ids(model_name, "happy")[0],
    "sad": get_token_ids(model_name, "sad")[0],
    "neutral": get_token_ids(model_name, "neutral")[0],
}


# %% make a simple query
prompt = "H"
client = OpenAI()
# model_name = "gpt-3.5-turbo-1106"
completions = {}
for model_name in [
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-0301",
    "gpt-3.5-turbo-0613",
    "gpt-4-1106-preview",
    "gpt-4-0314",
    "gpt-4-0613",
]:
    completion = client.chat.completions.create(
        model=model_name,
        seed=42,
        messages=[
            {"role": "user", "content": prompt},
        ],
        max_tokens=1,
        temperature=0,
        logprobs=True,
        top_logprobs=5,
    )

    completions[model_name] = completion


# %%
prompt_tokens = {}
for model_name in completions:
    prompt_tokens[model_name] = completion.usage.prompt_tokens
    print(f"Prompt tokens for {model_name}: {prompt_tokens[model_name]}")

# dump the completions list as a json
import json

json_completions = {}
for model_name in completions:
    json_completions[model_name] = json.loads(completion.model_dump_json())
# now this is a string, parse it back to json
with open("proves_7_additional_chat_tokens.json", "w") as f:
    json.dump(json_completions, f, indent=4)


# %%
model_name = "gpt-3.5-turbo-1106"
print(json_completions[model_name])


# %%
"""
logit_bias
map
Optional
Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
"""


# Continue the code with setting a logit_bias for a specific token

# %%
# Iterate while modifying the offset; log all results in a dict (save system_fingerprint and choices[0].message)
results = {}
import numpy as np

offset = 0.2
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "How do you feel?"},
]
# completion = client.chat.completions.create(model="gpt-3.5-turbo-1106", seed=42, messages=messages, max_tokens=10, temperature=0,
#  logit_bias={str(logit_bias_values['happy']): offset, str(logit_bias_values['sad']): offset, str(logit_bias_values['neutral']): offset},
# )
# print(completion.system_fingerprint)
# print(completion.choices[0].message)


# %%
# %%
def format_float(x) -> str:
    return "{:.3f}".format(x)


# %%
# Ensure logit_bias_values is defined somewhere in your code

client = AsyncOpenAI(timeout=10.0, max_retries=1)


async def main() -> None:
    results = {}

    for offset in np.arange(26.5, 28.0, 0.09):
        results[format_float(offset)] = {}
        try:
            completion = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                seed=42,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "How do you feel?"},
                ],
                max_tokens=10,
                temperature=0,
                # logit_bias={
                #    str(logit_bias_values['happy']): offset,
                #    str(logit_bias_values['sad']): offset,
                #    str(logit_bias_values['neutral']): offset,
                # },
                # all number tokens
                logit_bias={str(x): offset for x in range(0, 500)},
            )

            # Assuming the API response structure is correct
            print(format_float(offset))
            print(completion.system_fingerprint)
            print(completion.choices[0].message)

            # Store results
            results[format_float(offset)]["completion"] = completion.model_dump()
        except Exception as e:
            results[format_float(offset)]["error"] = str(e)

    # %%
    print(results)
    import json

    json.dump(results, open("results.json", "w"), indent=4)


# %%
asyncio.run(main())

# %
# %%
